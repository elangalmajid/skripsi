{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8ee9e8",
   "metadata": {},
   "source": [
    "# Coffee Bean Classification with **GNN (Superpixel Graph)**\n",
    "Notebook ini mengubah pendekatan **CNN** menjadi **Graph Neural Network (GNN)** menggunakan **superpixel** sebagai node dan **k-NN** sebagai edge. Library utama: `spektral` (untuk GNN berbasis Keras/TensorFlow) dan `scikit-image` (untuk superpixel SLIC).\n",
    "    \n",
    "> **Struktur dataset yang diharapkan**\n",
    ">\n",
    "> ```\n",
    "> Dataset/\n",
    "> ├── train/\n",
    "> │   ├── ClassA/\n",
    "> │   │   ├── img1.jpg\n",
    "> │   │   └── ...\n",
    "> │   ├── ClassB/\n",
    "> │   └── ...\n",
    "> ├── val/\n",
    "> └── test/\n",
    "> ```\n",
    ">\n",
    "> Setiap subfolder mewakili **label**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opsional) Install dependencies - jalankan jika environment belum punya paket ini\n",
    "# Jika sudah terpasang, Anda bisa melewati cell ini.\n",
    "# Catatan: Pada beberapa environment offline, perintah ini perlu dijalankan manual.\n",
    "# !pip -q install spektral scikit-image scikit-learn tensorflow==2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e276e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spektral'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msegmentation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m slic\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NearestNeighbors\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspektral\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, Graph\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspektral\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DisjointLoader\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspektral\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GlobalSumPool\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spektral'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage import io, transform, color\n",
    "from skimage.segmentation import slic\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.data.loaders import DisjointLoader\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41afbf3",
   "metadata": {},
   "source": [
    "## Konfigurasi & Path Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah path sesuai struktur Anda\n",
    "training_path = \"Dataset/train\"\n",
    "validation_path = \"Dataset/valid\"\n",
    "testing_path = \"Dataset/test\"\n",
    "\n",
    "# Hyperparameters GNN & Preprocessing\n",
    "IMG_SIZE = 256            # resize awal gambar sebelum SLIC\n",
    "N_SEGMENTS = 120          # jumlah superpixel (node) per gambar\n",
    "COMPACTNESS = 10.0        # parameter SLIC\n",
    "KNN_K = 8                 # jumlah tetangga untuk edge\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Fitur node: [L, a, b, x_norm, y_norm, std_L, std_a, std_b] -> 8 fitur\n",
    "FEATURES_DIM = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d239b",
   "metadata": {},
   "source": [
    "## Utilitas: Listing file & mapping label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0575c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_labels(root_dir):\n",
    "    \"\"\"Mengembalikan list (filepath, label_id) dan peta label_id -> label_name.\"\"\"\n",
    "    classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "    label_to_id = {c: i for i, c in enumerate(classes)}\n",
    "    id_to_label = {i: c for c, i in label_to_id.items()}\n",
    "    \n",
    "    files = []\n",
    "    for c in classes:\n",
    "        folder = os.path.join(root_dir, c)\n",
    "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\", \"*.webp\"):\n",
    "            for f in glob.glob(os.path.join(folder, ext)):\n",
    "                files.append((f, label_to_id[c]))\n",
    "    return files, id_to_label\n",
    "\n",
    "def load_image(path, img_size=256):\n",
    "    img = io.imread(path)\n",
    "    if img.ndim == 2:  # grayscale -> RGB\n",
    "        img = np.stack([img, img, img], axis=-1)\n",
    "    if img.shape[-1] == 4:  # RGBA -> RGB\n",
    "        img = img[..., :3]\n",
    "    img = transform.resize(img, (img_size, img_size), anti_aliasing=True, preserve_range=True)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def image_to_superpixel_graph(img, n_segments=120, compactness=10.0, knn_k=8):\n",
    "    \"\"\"Konversi gambar menjadi graph:\n",
    "    - Node: superpixel dari SLIC\n",
    "    - Fitur node: mean Lab (L,a,b), posisi (x,y) ter-normalisasi, dan std Lab\n",
    "    - Edge: k-NN pada centroid superpixel\n",
    "    Mengembalikan X (n_nodes x F), A (n_nodes x n_nodes)\n",
    "    \"\"\"\n",
    "    # Segmentasi superpixel\n",
    "    segments = slic(img, n_segments=n_segments, compactness=compactness, start_label=0, channel_axis=-1)\n",
    "    n_nodes = segments.max() + 1\n",
    "    \n",
    "    # Konversi ke ruang warna Lab untuk fitur yang lebih stabil\n",
    "    img_lab = color.rgb2lab(img)\n",
    "    \n",
    "    # Hitung fitur per superpixel\n",
    "    X = np.zeros((n_nodes, 8), dtype=np.float32)\n",
    "    centroids = np.zeros((n_nodes, 2), dtype=np.float32)  # (y, x)\n",
    "    \n",
    "    for seg_id in range(n_nodes):\n",
    "        mask = segments == seg_id\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        # Mean & std Lab\n",
    "        L = img_lab[..., 0][mask]\n",
    "        a = img_lab[..., 1][mask]\n",
    "        b = img_lab[..., 2][mask]\n",
    "        Lm, am, bm = L.mean(), a.mean(), b.mean()\n",
    "        Ls, as_, bs = L.std() if L.size > 1 else 0.0, a.std() if a.size > 1 else 0.0, b.std() if b.size > 1 else 0.0\n",
    "        \n",
    "        # Centroid posisi (y, x)\n",
    "        ys, xs = np.where(mask)\n",
    "        cy, cx = ys.mean(), xs.mean()\n",
    "        h, w = img.shape[:2]\n",
    "        cy_n, cx_n = cy / h, cx / w  # normalisasi 0..1\n",
    "        \n",
    "        X[seg_id] = [Lm, am, bm, cx_n, cy_n, Ls, as_, bs]\n",
    "        centroids[seg_id] = [cy, cx]\n",
    "    \n",
    "    # Edge dengan k-NN (euclidean) pada centroid\n",
    "    k = min(knn_k + 1, n_nodes)  # +1 untuk self, nanti dibuang\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, metric='euclidean').fit(centroids)\n",
    "    indices = nbrs.kneighbors(return_distance=False)\n",
    "    \n",
    "    A = np.zeros((n_nodes, n_nodes), dtype=np.float32)\n",
    "    for i in range(n_nodes):\n",
    "        for j in indices[i]:\n",
    "            if i == j:\n",
    "                continue\n",
    "            A[i, j] = 1.0\n",
    "            A[j, i] = 1.0  # undirected\n",
    "    \n",
    "    # (Opsional) normalisasi fitur per-graf agar skala seragam\n",
    "    # X = (X - X.mean(0, keepdims=True)) / (X.std(0, keepdims=True) + 1e-6)\n",
    "    return X, A\n",
    "\n",
    "# Cek cepat\n",
    "# test_img = np.ones((256,256,3), dtype=np.float32)\n",
    "# X, A = image_to_superpixel_graph(test_img, n_segments=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ab514",
   "metadata": {},
   "source": [
    "## Dataset Kustom untuk Spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoffeeSuperpixelDataset(Dataset):\n",
    "    def __init__(self, root_dir, img_size=IMG_SIZE, n_segments=N_SEGMENTS, compactness=COMPACTNESS, knn_k=KNN_K, **kwargs):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_size = img_size\n",
    "        self.n_segments = n_segments\n",
    "        self.compactness = compactness\n",
    "        self.knn_k = knn_k\n",
    "        \n",
    "        self.files_labels, self.id_to_label = list_files_labels(root_dir)\n",
    "        self.n_classes = len(self.id_to_label)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        graphs = []\n",
    "        for fp, y_id in self.files_labels:\n",
    "            img = load_image(fp, self.img_size)\n",
    "            X, A = image_to_superpixel_graph(img, self.n_segments, self.compactness, self.knn_k)\n",
    "            y = tf.keras.utils.to_categorical(y_id, num_classes=self.n_classes).astype(np.float32)\n",
    "            graphs.append(Graph(x=X, a=A, y=y))\n",
    "        return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ddc12a",
   "metadata": {},
   "source": [
    "## Bangun Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets\n",
    "train_ds = CoffeeSuperpixelDataset(training_path)\n",
    "val_ds   = CoffeeSuperpixelDataset(validation_path)\n",
    "test_ds  = CoffeeSuperpixelDataset(testing_path)\n",
    "\n",
    "N_CLASSES = train_ds.n_classes\n",
    "print(\"Classes:\", [train_ds.id_to_label[i] for i in range(N_CLASSES)])\n",
    "print(f\"Train graphs: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
    "\n",
    "# Loaders (disjoint) untuk batch graph ukuran variabel\n",
    "train_loader = DisjointLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DisjointLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DisjointLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b43248",
   "metadata": {},
   "source": [
    "## Arsitektur GNN (GCN + Global Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model GNN sederhana dengan GCNConv\n",
    "# Input mengikuti format 'disjoint' dari Spektral: [X, A, I] (fit() otomatis dari DisjointLoader)\n",
    "\n",
    "class GNNModel(Model):\n",
    "    def __init__(self, n_classes, hidden=128, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(hidden, activation='relu')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.drop1 = Dropout(dropout_rate)\n",
    "        \n",
    "        self.gcn2 = GCNConv(hidden, activation='relu')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.drop2 = Dropout(dropout_rate)\n",
    "        \n",
    "        self.pool = GlobalSumPool()\n",
    "        self.out_dense1 = Dense(128, activation='relu')\n",
    "        self.drop3 = Dropout(dropout_rate)\n",
    "        self.out = Dense(n_classes, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, a, i = inputs\n",
    "        x = self.gcn1([x, a])\n",
    "        x = self.bn1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.gcn2([x, a])\n",
    "        x = self.bn2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.pool([x, i])\n",
    "        x = self.out_dense1(x)\n",
    "        x = self.drop3(x)\n",
    "        return self.out(x)\n",
    "\n",
    "model = GNNModel(N_CLASSES, hidden=128, dropout_rate=0.3)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=[(None, None, FEATURES_DIM), (None, None), (None,)])  # for summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff4df2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ffbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_loader.load(),\n",
    "    steps_per_epoch=train_loader.steps_per_epoch,\n",
    "    validation_data=val_loader.load(),\n",
    "    validation_steps=val_loader.steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8e8df",
   "metadata": {},
   "source": [
    "## Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db22655",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluasi pada test set:\")\n",
    "test_results = model.evaluate(\n",
    "    test_loader.load(),\n",
    "    steps=test_loader.steps_per_epoch,\n",
    "    verbose=1\n",
    ")\n",
    "print(dict(zip(model.metrics_names, test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ba56f",
   "metadata": {},
   "source": [
    "## Inferensi Contoh & Visualisasi Superpixel (Opsional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76559d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan prediksi dan visualisasi superpixel untuk beberapa contoh dari test set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_superpixels(path):\n",
    "    img = load_image(path, IMG_SIZE)\n",
    "    segments = slic(img, n_segments=N_SEGMENTS, compactness=COMPACTNESS, start_label=0, channel_axis=-1)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.contour(segments, colors='white', linewidths=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title('Superpixel SLIC')\n",
    "    plt.show()\n",
    "\n",
    "# Ambil 3 file acak dari test set\n",
    "test_files = [fp for fp, _ in test_ds.files_labels]\n",
    "random.shuffle(test_files)\n",
    "for fp in test_files[:3]:\n",
    "    img = load_image(fp, IMG_SIZE)\n",
    "    X, A = image_to_superpixel_graph(img, N_SEGMENTS, COMPACTNESS, KNN_K)\n",
    "    # Spektral meminta 'i' (graph indicator) untuk batch 1 graf -> zeros\n",
    "    I = np.zeros((X.shape[0],), dtype=np.int64)\n",
    "    pred = model.predict([X[np.newaxis, ...], A[np.newaxis, ...], I[np.newaxis, ...]], verbose=0)[0]\n",
    "    pred_id = pred.argmax()\n",
    "    label_name = test_ds.id_to_label[pred_id]\n",
    "    print(f\"Prediksi: {label_name} (p={pred[pred_id]:.3f}) — file: {os.path.basename(fp)}\")\n",
    "    visualize_superpixels(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c25973",
   "metadata": {},
   "source": [
    "## Catatan & Tips\n",
    "- **N_SEGMENTS** (jumlah superpixel) trade-off antara detail vs waktu komputasi. Coba 80–200.\n",
    "- **KNN_K** mengontrol kepadatan edge. Nilai 6–10 umumnya stabil.\n",
    "- Tambahkan **augmentasi** di level gambar sebelum SLIC untuk memperkaya variasi (flip/rotate).\n",
    "- Coba layer lain: `GraphSageConv`, `GATConv` (Spektral) untuk eksplorasi arsitektur.\n",
    "- Anda bisa menyimpan **label map** via `train_ds.id_to_label` untuk digunakan saat deployment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
