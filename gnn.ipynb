{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import helpers\n",
    "from PIL import Image, ImageFile\n",
    "from timeit import default_timer as timer\n",
    "from pathlib import Path\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from model_vig import vig_ti_224_gelu\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from helpers import plot_loss_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6545442",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92767e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path(\"Dataset/train/\")\n",
    "test_dir = Path(\"Dataset/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8930da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocess = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.RandomErasing(p=0.25),\n",
    "    v2.RandAugment(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_preprpocess = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ee1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(str(train_dir), transform=train_preprocess)\n",
    "test_dataset = datasets.ImageFolder(str(test_dir), transform=test_preprpocess)\n",
    "class_names = train_dataset.classes\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529ba886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpr [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "num_knn [9, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "model = vig_ti_224_gelu(num_classes=len(class_names)).to(device)\n",
    "LEARNING_RATE = 0.002\n",
    "NUM_EPOCHS = 50\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "num_training_steps = NUM_EPOCHS * len(train_dataloader)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e4070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "model: torch.nn.Module,\n",
    "dataloader: torch.utils.data.DataLoader,\n",
    "loss_fn: torch.nn.Module,\n",
    "optimizer: torch.optim.Optimizer,\n",
    "device: torch.device,\n",
    "progress_bar: tqdm | None = None,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred,\n",
    "        dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        if progress_bar:\n",
    "            progress_bar.update(1)\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfc0fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "model: torch.nn.Module,\n",
    "dataloader: torch.utils.data.DataLoader,\n",
    "loss_fn: torch.nn.Module,\n",
    "device: torch.device,\n",
    "progress_bar: tqdm | None = None,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred_logits = model(X)\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
    "            if progress_bar:\n",
    "                progress_bar.update(1)\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cac80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    use_progress_bar: bool = False,\n",
    ") -> Dict[str, List]:\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\":\n",
    "    [], \"test_acc\": []}\n",
    "    if use_progress_bar:\n",
    "        progress_bar = tqdm(\n",
    "            total=len(train_dataloader) + len(test_dataloader),\n",
    "            desc=\"Processing Batch\"\n",
    "    )\n",
    "    for epoch in tqdm(range(epochs), desc=\"Processing Epoch\"):\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            progress_bar=progress_bar if use_progress_bar else\n",
    "            None,\n",
    "        )\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device,\n",
    "            progress_bar=progress_bar if use_progress_bar else\n",
    "            None,\n",
    "        )\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | Train loss: {train_loss:.5f} | Test loss: {test_loss:.5f} | Train acc: {train_acc*100:.2f}% | Test acc: {test_acc*100:.2f}% | LR: {lr_scheduler.get_last_lr()}\"\n",
    "        )\n",
    "        progress_bar.reset()\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = timer()\n",
    "results = train(\n",
    "    model=model.to(device),\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    device=torch.device(device),\n",
    "    use_progress_bar=True,\n",
    ")\n",
    "end_time = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2950a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"./models/eksperimen_3_vig.pth\")\n",
    "torch.save({\"epoch\": NUM_EPOCHS,\n",
    "\"model_state_dict\": model.state_dict(),\n",
    "\"optimizer_state_dict\": optimizer.state_dict(),},\n",
    "save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
